{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Problem - Classify Cat vs Dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#code from keras documentation - https://keras.io/preprocessing/image/\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#Image augmentation - rotate, shift, flip, etc.. copies of image to expand size of training set\n",
    "#rescale in a range from zero to 1\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_data_generator.flow_from_directory('dataset/training_set',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('dataset/test_set',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "#Initializing the Convolutional Neural Network\n",
    "\n",
    "def build_cnn():\n",
    "    #Step 1 - Convolution\n",
    "    classifier = Sequential()\n",
    "\n",
    "    #add feature detector number of rows and columns as kernel size parameter\n",
    "    #image 64 x 64 with 3 color channels\n",
    "    #relu activation function to remove linearity\n",
    "    cnn_input_layer = Conv2D(filters = 32, kernel_size = (3, 3), input_shape = (128, 128, 3), activation = 'relu')\n",
    "    classifier.add(cnn_input_layer)\n",
    "    #Step 2 - Max Pooling\n",
    "\n",
    "    #reduce size of feature maps using max pooling\n",
    "    max_pooling_layer = MaxPooling2D(pool_size = (2, 2))\n",
    "    classifier.add(max_pooling_layer)\n",
    "    \n",
    "    #Create Deep Fully Connected Layers (hidden layers) - 2nd Layer\n",
    "    fcl = Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu')\n",
    "    classifier.add(fcl)\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    \n",
    "    fcl2 = Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu')\n",
    "    classifier.add(fcl2)\n",
    "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "    #Step 3 - Flattening\n",
    "    flattening_layer = Flatten()\n",
    "    classifier.add(flattening_layer)\n",
    "\n",
    "    #Step 4 - Full Connection\n",
    "    ann_fully_connected_layer = Dense(units = 128, activation = 'relu') #same as ANN hidden layer\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    classifier.add(ann_fully_connected_layer)\n",
    "\n",
    "    ann_output_layer = Dense(units = 1, activation = 'sigmoid')\n",
    "    classifier.add(ann_output_layer)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = build_cnn()\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/90\n",
      "250/250 [==============================] - 86s 344ms/step - loss: 0.6891 - accuracy: 0.5290 - val_loss: 0.7270 - val_accuracy: 0.5900\n",
      "Epoch 2/90\n",
      "250/250 [==============================] - 85s 341ms/step - loss: 0.6440 - accuracy: 0.6314 - val_loss: 0.5730 - val_accuracy: 0.6970\n",
      "Epoch 3/90\n",
      "250/250 [==============================] - 146s 583ms/step - loss: 0.5887 - accuracy: 0.6821 - val_loss: 0.6062 - val_accuracy: 0.7165\n",
      "Epoch 4/90\n",
      "250/250 [==============================] - 82s 327ms/step - loss: 0.5460 - accuracy: 0.7226 - val_loss: 0.7758 - val_accuracy: 0.7180\n",
      "Epoch 5/90\n",
      "250/250 [==============================] - 78s 313ms/step - loss: 0.5167 - accuracy: 0.7401 - val_loss: 0.2891 - val_accuracy: 0.7650\n",
      "Epoch 6/90\n",
      "250/250 [==============================] - 80s 319ms/step - loss: 0.4969 - accuracy: 0.7580 - val_loss: 0.3818 - val_accuracy: 0.7725\n",
      "Epoch 7/90\n",
      "250/250 [==============================] - 86s 344ms/step - loss: 0.4632 - accuracy: 0.7822 - val_loss: 0.4082 - val_accuracy: 0.7805\n",
      "Epoch 8/90\n",
      "250/250 [==============================] - 112s 447ms/step - loss: 0.4469 - accuracy: 0.7924 - val_loss: 0.4002 - val_accuracy: 0.7970\n",
      "Epoch 9/90\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 0.4282 - accuracy: 0.7994 - val_loss: 0.5621 - val_accuracy: 0.8040\n",
      "Epoch 10/90\n",
      "250/250 [==============================] - 87s 349ms/step - loss: 0.4092 - accuracy: 0.8112 - val_loss: 0.6522 - val_accuracy: 0.7990\n",
      "Epoch 11/90\n",
      "250/250 [==============================] - 88s 350ms/step - loss: 0.3943 - accuracy: 0.8200 - val_loss: 0.3393 - val_accuracy: 0.8175\n",
      "Epoch 12/90\n",
      "250/250 [==============================] - 98s 394ms/step - loss: 0.3721 - accuracy: 0.8345 - val_loss: 0.1697 - val_accuracy: 0.8160\n",
      "Epoch 13/90\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 0.3718 - accuracy: 0.8309 - val_loss: 0.7164 - val_accuracy: 0.8105\n",
      "Epoch 14/90\n",
      "250/250 [==============================] - 101s 406ms/step - loss: 0.3522 - accuracy: 0.8424 - val_loss: 0.6348 - val_accuracy: 0.8320\n",
      "Epoch 15/90\n",
      "250/250 [==============================] - 102s 406ms/step - loss: 0.3331 - accuracy: 0.8556 - val_loss: 0.4909 - val_accuracy: 0.8310\n",
      "Epoch 16/90\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 0.3241 - accuracy: 0.8555 - val_loss: 0.2299 - val_accuracy: 0.8335\n",
      "Epoch 17/90\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 0.3177 - accuracy: 0.8604 - val_loss: 0.7174 - val_accuracy: 0.8275\n",
      "Epoch 18/90\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 0.3046 - accuracy: 0.8687 - val_loss: 0.5731 - val_accuracy: 0.8380\n",
      "Epoch 19/90\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 0.2849 - accuracy: 0.8755 - val_loss: 0.3946 - val_accuracy: 0.8405\n",
      "Epoch 20/90\n",
      "250/250 [==============================] - 102s 407ms/step - loss: 0.2802 - accuracy: 0.8789 - val_loss: 0.3021 - val_accuracy: 0.8340\n",
      "Epoch 21/90\n",
      "250/250 [==============================] - 101s 405ms/step - loss: 0.2643 - accuracy: 0.8905 - val_loss: 0.1542 - val_accuracy: 0.8315\n",
      "Epoch 22/90\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 0.2671 - accuracy: 0.8823 - val_loss: 0.2630 - val_accuracy: 0.8450\n",
      "Epoch 23/90\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 0.2524 - accuracy: 0.8946 - val_loss: 0.2018 - val_accuracy: 0.8415\n",
      "Epoch 24/90\n",
      "250/250 [==============================] - 101s 402ms/step - loss: 0.2478 - accuracy: 0.8926 - val_loss: 0.2270 - val_accuracy: 0.8025\n",
      "Epoch 25/90\n",
      "250/250 [==============================] - 101s 405ms/step - loss: 0.2263 - accuracy: 0.9099 - val_loss: 0.5882 - val_accuracy: 0.8435\n",
      "Epoch 26/90\n",
      "250/250 [==============================] - 103s 410ms/step - loss: 0.2325 - accuracy: 0.9035 - val_loss: 0.3857 - val_accuracy: 0.8490\n",
      "Epoch 27/90\n",
      "250/250 [==============================] - 101s 404ms/step - loss: 0.2037 - accuracy: 0.9185 - val_loss: 0.5517 - val_accuracy: 0.8325\n",
      "Epoch 28/90\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 0.2035 - accuracy: 0.9120 - val_loss: 0.1790 - val_accuracy: 0.8475\n",
      "Epoch 29/90\n",
      "250/250 [==============================] - 103s 412ms/step - loss: 0.1966 - accuracy: 0.9189 - val_loss: 0.4877 - val_accuracy: 0.8040\n",
      "Epoch 30/90\n",
      "250/250 [==============================] - 88s 351ms/step - loss: 0.1884 - accuracy: 0.9215 - val_loss: 0.1347 - val_accuracy: 0.8385\n",
      "Epoch 31/90\n",
      "250/250 [==============================] - 87s 348ms/step - loss: 0.1831 - accuracy: 0.9222 - val_loss: 0.4661 - val_accuracy: 0.8425\n",
      "Epoch 32/90\n",
      "250/250 [==============================] - 103s 411ms/step - loss: 0.1746 - accuracy: 0.9294 - val_loss: 0.3574 - val_accuracy: 0.8485\n",
      "Epoch 33/90\n",
      "250/250 [==============================] - 107s 427ms/step - loss: 0.1616 - accuracy: 0.9346 - val_loss: 0.3105 - val_accuracy: 0.8305\n",
      "Epoch 34/90\n",
      "250/250 [==============================] - 95s 380ms/step - loss: 0.1623 - accuracy: 0.9334 - val_loss: 0.6068 - val_accuracy: 0.8395\n",
      "Epoch 35/90\n",
      "250/250 [==============================] - 92s 369ms/step - loss: 0.1708 - accuracy: 0.9300 - val_loss: 0.1025 - val_accuracy: 0.8370\n",
      "Epoch 36/90\n",
      "250/250 [==============================] - 92s 370ms/step - loss: 0.1506 - accuracy: 0.9396 - val_loss: 0.2994 - val_accuracy: 0.8360\n",
      "Epoch 37/90\n",
      "250/250 [==============================] - 93s 372ms/step - loss: 0.1395 - accuracy: 0.9457 - val_loss: 0.1896 - val_accuracy: 0.8420\n",
      "Epoch 38/90\n",
      "250/250 [==============================] - 95s 379ms/step - loss: 0.1379 - accuracy: 0.9490 - val_loss: 0.1930 - val_accuracy: 0.8335\n",
      "Epoch 39/90\n",
      "250/250 [==============================] - 97s 388ms/step - loss: 0.1339 - accuracy: 0.9498 - val_loss: 0.2133 - val_accuracy: 0.8380\n",
      "Epoch 40/90\n",
      "250/250 [==============================] - 95s 382ms/step - loss: 0.1281 - accuracy: 0.9519 - val_loss: 0.0395 - val_accuracy: 0.8330\n",
      "Epoch 41/90\n",
      "250/250 [==============================] - 95s 381ms/step - loss: 0.1221 - accuracy: 0.9516 - val_loss: 0.1694 - val_accuracy: 0.8485\n",
      "Epoch 42/90\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 0.1234 - accuracy: 0.9525 - val_loss: 1.1011 - val_accuracy: 0.8405\n",
      "Epoch 43/90\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 0.1193 - accuracy: 0.9524 - val_loss: 0.5909 - val_accuracy: 0.8285\n",
      "Epoch 44/90\n",
      "250/250 [==============================] - 96s 385ms/step - loss: 0.1147 - accuracy: 0.9525 - val_loss: 2.6358 - val_accuracy: 0.8525\n",
      "Epoch 45/90\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.1180 - accuracy: 0.9546 - val_loss: 0.4305 - val_accuracy: 0.8405\n",
      "Epoch 46/90\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 0.1118 - accuracy: 0.9551 - val_loss: 0.6200 - val_accuracy: 0.8390\n",
      "Epoch 47/90\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 0.1084 - accuracy: 0.9609 - val_loss: 0.7267 - val_accuracy: 0.8445\n",
      "Epoch 48/90\n",
      "250/250 [==============================] - 95s 382ms/step - loss: 0.0972 - accuracy: 0.9632 - val_loss: 0.0869 - val_accuracy: 0.8430\n",
      "Epoch 49/90\n",
      "250/250 [==============================] - 95s 381ms/step - loss: 0.0975 - accuracy: 0.9616 - val_loss: 0.1444 - val_accuracy: 0.8565\n",
      "Epoch 50/90\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 0.0957 - accuracy: 0.9654 - val_loss: 0.2584 - val_accuracy: 0.8460\n",
      "Epoch 51/90\n",
      "250/250 [==============================] - 97s 386ms/step - loss: 0.0975 - accuracy: 0.9655 - val_loss: 0.6628 - val_accuracy: 0.8385\n",
      "Epoch 52/90\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 0.0886 - accuracy: 0.9670 - val_loss: 0.9018 - val_accuracy: 0.8490\n",
      "Epoch 53/90\n",
      "250/250 [==============================] - 95s 382ms/step - loss: 0.0825 - accuracy: 0.9682 - val_loss: 0.4652 - val_accuracy: 0.8410\n",
      "Epoch 54/90\n",
      "250/250 [==============================] - 95s 381ms/step - loss: 0.0822 - accuracy: 0.9694 - val_loss: 0.2036 - val_accuracy: 0.8510\n",
      "Epoch 55/90\n",
      "250/250 [==============================] - 95s 381ms/step - loss: 0.0904 - accuracy: 0.9666 - val_loss: 1.0502 - val_accuracy: 0.8410\n",
      "Epoch 56/90\n",
      "250/250 [==============================] - 99s 395ms/step - loss: 0.0912 - accuracy: 0.9665 - val_loss: 0.9476 - val_accuracy: 0.8300\n",
      "Epoch 57/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 94s 374ms/step - loss: 0.0916 - accuracy: 0.9678 - val_loss: 0.2870 - val_accuracy: 0.8505\n",
      "Epoch 58/90\n",
      "250/250 [==============================] - 88s 353ms/step - loss: 0.0861 - accuracy: 0.9691 - val_loss: 0.5855 - val_accuracy: 0.8575\n",
      "Epoch 59/90\n",
      "250/250 [==============================] - 92s 370ms/step - loss: 0.0750 - accuracy: 0.9715 - val_loss: 0.1944 - val_accuracy: 0.8460\n",
      "Epoch 60/90\n",
      "250/250 [==============================] - 105s 421ms/step - loss: 0.0721 - accuracy: 0.9731 - val_loss: 0.5890 - val_accuracy: 0.8435\n",
      "Epoch 61/90\n",
      "250/250 [==============================] - 104s 416ms/step - loss: 0.0716 - accuracy: 0.9741 - val_loss: 0.0266 - val_accuracy: 0.8455\n",
      "Epoch 62/90\n",
      "250/250 [==============================] - 96s 385ms/step - loss: 0.0855 - accuracy: 0.9695 - val_loss: 0.9776 - val_accuracy: 0.8345\n",
      "Epoch 63/90\n",
      "250/250 [==============================] - 96s 386ms/step - loss: 0.0755 - accuracy: 0.9744 - val_loss: 1.1147 - val_accuracy: 0.8500\n",
      "Epoch 64/90\n",
      "250/250 [==============================] - 97s 388ms/step - loss: 0.0736 - accuracy: 0.9715 - val_loss: 0.0715 - val_accuracy: 0.8415\n",
      "Epoch 65/90\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 0.0745 - accuracy: 0.9729 - val_loss: 0.8386 - val_accuracy: 0.8475\n",
      "Epoch 66/90\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 0.0640 - accuracy: 0.9755 - val_loss: 1.0841 - val_accuracy: 0.8380\n",
      "Epoch 67/90\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 0.0781 - accuracy: 0.9712 - val_loss: 0.1412 - val_accuracy: 0.8460\n",
      "Epoch 68/90\n",
      "250/250 [==============================] - 96s 382ms/step - loss: 0.0624 - accuracy: 0.9759 - val_loss: 0.1231 - val_accuracy: 0.8500\n",
      "Epoch 69/90\n",
      "250/250 [==============================] - 96s 383ms/step - loss: 0.0730 - accuracy: 0.9730 - val_loss: 1.2324 - val_accuracy: 0.8380\n",
      "Epoch 70/90\n",
      "250/250 [==============================] - 97s 389ms/step - loss: 0.0635 - accuracy: 0.9766 - val_loss: 0.7424 - val_accuracy: 0.8485\n",
      "Epoch 71/90\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 0.0634 - accuracy: 0.9762 - val_loss: 0.2891 - val_accuracy: 0.8500\n",
      "Epoch 72/90\n",
      "250/250 [==============================] - 98s 391ms/step - loss: 0.0555 - accuracy: 0.9810 - val_loss: 0.8481 - val_accuracy: 0.8400\n",
      "Epoch 73/90\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 0.0557 - accuracy: 0.9780 - val_loss: 0.3854 - val_accuracy: 0.8395\n",
      "Epoch 74/90\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 0.0683 - accuracy: 0.9760 - val_loss: 0.3619 - val_accuracy: 0.8410\n",
      "Epoch 75/90\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 0.0733 - accuracy: 0.9744 - val_loss: 1.2561 - val_accuracy: 0.8400\n",
      "Epoch 76/90\n",
      "250/250 [==============================] - 99s 396ms/step - loss: 0.0534 - accuracy: 0.9811 - val_loss: 0.9701 - val_accuracy: 0.8425\n",
      "Epoch 77/90\n",
      "250/250 [==============================] - 97s 389ms/step - loss: 0.0607 - accuracy: 0.9764 - val_loss: 0.5054 - val_accuracy: 0.8305\n",
      "Epoch 78/90\n",
      "250/250 [==============================] - 97s 389ms/step - loss: 0.0594 - accuracy: 0.9770 - val_loss: 1.7213 - val_accuracy: 0.8465\n",
      "Epoch 79/90\n",
      "250/250 [==============================] - 98s 391ms/step - loss: 0.0541 - accuracy: 0.9805 - val_loss: 0.0906 - val_accuracy: 0.8350\n",
      "Epoch 80/90\n",
      "250/250 [==============================] - 98s 391ms/step - loss: 0.0562 - accuracy: 0.9797 - val_loss: 0.4813 - val_accuracy: 0.8520\n",
      "Epoch 81/90\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 0.0559 - accuracy: 0.9806 - val_loss: 0.1694 - val_accuracy: 0.8410\n",
      "Epoch 82/90\n",
      "250/250 [==============================] - 101s 406ms/step - loss: 0.0572 - accuracy: 0.9796 - val_loss: 0.9779 - val_accuracy: 0.8465\n",
      "Epoch 83/90\n",
      "250/250 [==============================] - 100s 399ms/step - loss: 0.0591 - accuracy: 0.9804 - val_loss: 1.7391 - val_accuracy: 0.8400\n",
      "Epoch 84/90\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 0.0450 - accuracy: 0.9849 - val_loss: 0.4931 - val_accuracy: 0.8360\n",
      "Epoch 85/90\n",
      "250/250 [==============================] - 98s 391ms/step - loss: 0.0601 - accuracy: 0.9771 - val_loss: 0.3884 - val_accuracy: 0.8475\n",
      "Epoch 86/90\n",
      "250/250 [==============================] - 98s 391ms/step - loss: 0.0575 - accuracy: 0.9794 - val_loss: 0.4062 - val_accuracy: 0.8465\n",
      "Epoch 87/90\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 0.0505 - accuracy: 0.9819 - val_loss: 0.0781 - val_accuracy: 0.8465\n",
      "Epoch 88/90\n",
      "250/250 [==============================] - 99s 394ms/step - loss: 0.0578 - accuracy: 0.9796 - val_loss: 1.9188 - val_accuracy: 0.8335\n",
      "Epoch 89/90\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 0.0561 - accuracy: 0.9803 - val_loss: 0.4582 - val_accuracy: 0.8465\n",
      "Epoch 90/90\n",
      "250/250 [==============================] - 98s 390ms/step - loss: 0.0533 - accuracy: 0.9816 - val_loss: 0.0919 - val_accuracy: 0.8385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ad86c1ef60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "classifier.fit_generator(generator = train_generator, steps_per_epoch = 8000/batch_size, epochs = 90, validation_data = test_generator, workers = 16, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making new prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#Load Image\n",
    "dog_or_cat_test1 = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size=(128, 128))\n",
    "dog_or_cat_test1 = image.img_to_array(dog_or_cat_test1)\n",
    "\n",
    "#add dimension for neural network prediction\n",
    "dog_or_cat_test1 = np.expand_dims(dog_or_cat_test1, axis = 0) #added to beginning of array\n",
    "#make prediction\n",
    "binary_result = classifier.predict(dog_or_cat_test1)\n",
    "binary_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
